# emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode:nil -*-
# vi: set ft=python sts=4 ts=4 sw=4 et:

import os
import numpy as np
import nibabel as nib
import pandas as pd
import csv
import random

def vox2MNI(vox,affine):
    vox_new = np.ones([4,1])
    vox_new[0:-1,0] = vox[:]
    MNI = affine.dot(vox_new)
    MNI_new = MNI[0:-1].tolist()    # transform array into list
    return sum(MNI_new,[])  # extend multiple list

def dice(image1,image2):
    image1_instead = image1
    image2_instead = image2
    image1_instead[image1_instead!=0]=1
    image2_instead[image2_instead!=0]=1
    overlap = image1*image2
    dice_num = 2*overlap.sum()/(image1.sum()+image2.sum())
    return dice_num

def random_split_list(raw_list):
    length_list = len(raw_list)
    split_list = random.sample(raw_list,length_list)
    pre_splitlist = split_list[0:length_list/2]
    post_splitlist = split_list[length_list/2:]
    return pre_splitlist,post_splitlist
    
def bluring():
    pass    

def apply_loadimg(dirs):
    return map(lambda x: nib.load(x).get_data(), dirs)


def probatlas(sesspar,sessid,contrast,filename,lbname,lbid,outputdir):
    signals = [os.path.join(sesspar,sed,contrast,filename) for sed in sessid]
    ffsignals = apply_loadimg(signals)
    probdata = np.zeros([91,109,91,len(lbname)])
    header = nib.load(signals[0]).get_header()
    for areaid in lbid:   
        for sigid in range(len(signals)):
            probdata[:,:,:,areaid-1][ffsignals[sigid] == (areaid)] += 1
    probdata = probdata/len(sessid)
    for areaid in range(len(lbid)):
        img_new = nib.Nifti1Image(probdata[:,:,:,areaid],None,header)
        nib.save(img_new,outputdir + lbname[areaid] + '.nii.gz')    
    return probdata

def MPM(probdata,header,thr,outputdir):
    areasnum = probdata.shape[3]
    probdata_new = np.zeros([91,109,91,areasnum+1])
    probdata[probdata<thr] = 0 
    probdata_new[:,:,:,1:areasnum+1] = probdata
    mpmdata = probdata_new.argmax(axis=3) 
    img_new = nib.Nifti1Image(mpmdata,None,header)
    nib.save(img_new,outputdir+'MPM_p'+str(thr)+'.nii.gz')
    return mpmdata



# input variable,sesspar
sesspar = '/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/BAA/SSR'
# input variable,sessid
obj_file = open('/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/doc/dfsf/sub/subjID','rU')
sessid = obj_file.read().splitlines()
obj_file.close()
# output path
outpath = '/nfs/j3/userhome/huangtaicheng/workingdir/try_htc/mt_analysis/'
# lbname
areaname = ['rV3','lV3','rMT','lMT']
# lbid
areaid = [1,2,3,4]


#input variable,task
task = 'mt'
#input variable,contrast
contrast = 'motion'
idnum = len(sessid)
areanum = 4

volume = np.zeros([idnum,areanum])
mpsc = np.zeros([idnum,areanum])
mzstat = np.zeros([idnum,areanum])
ppsc = np.zeros([idnum,areanum])
pzstat = np.zeros([idnum,areanum])
peak_cor = np.zeros([idnum,areanum,3])
sessi = 0

# define pre and post index
pre_num = idnum/2
post_num = idnum - idnum/2
pre_volume = np.zeros([pre_num,areanum])
post_volume = np.zeros([post_num,areanum])
pre_mpsc = np.zeros([pre_num,areanum])
post_mpsc = np.zeros([post_num,areanum])
pre_ppsc = np.zeros([pre_num,areanum])
post_ppsc = np.zeros([post_num,areanum])
pre_mzstat = np.zeros([pre_num,areanum])
post_mzstat = np.zeros([post_num,areanum])
pre_pzstat = np.zeros([pre_num,areanum])
post_pzstat = np.zeros([post_num,areanum])
pre_peak_cor = np.zeros([pre_num,areanum,3])
post_peak_cor = np.zeros([post_num,areanum,3])


for sess in sessid:
    # Q1:how to express names of mt_z5.0_ff.nii.gz
    pathmt = os.path.join(sesspar,sess,task,contrast,'mt_z5.0_ff.nii.gz')
    # Q2:how to express names of cope1.nii.gz
    pathbeta = os.path.join(sesspar,sess,task,contrast,'cope1.nii.gz')
    pathstat = os.path.join(sesspar,sess,task,contrast,'zstat1.nii.gz')
    img_zsta = nib.load(pathstat)
    data_zsta = img_zsta.get_data()
    img_mt = nib.load(pathmt)
    data_mt = img_mt.get_data()
    img_beta = nib.load(pathbeta)
    data_beta = img_beta.get_data()    
    
    affine = img_zsta.get_affine()
    header = img_zsta.get_header()
    
    for areai in range(areanum):
  
        temp = np.zeros([91,109,91]) 
        volume[sessi,areai] = np.sum(data_mt == (areai+1))*(2*2*2)      
        if data_beta[data_mt == (areai+1)] != []:
            # mean psc has multiplied 100
            mpsc[sessi,areai] = np.nanmean(data_beta[data_mt == (areai+1)])/100
            # peak psc has multiplied 100
            ppsc[sessi,areai] = np.nanmax(data_beta[data_mt == (areai+1)])/100  
            # mean zstate value
            mzstat[sessi,areai] = np.nanmean(data_zsta[data_mt == (areai+1)]) 
            # peak zstate value
            pzstat[sessi,areai] = np.nanmax(data_zsta[data_mt == (areai+1)])
        # peak coordinate,need a middle variable 'temp'        
        temp[data_mt == (areai+1)] = data_zsta[data_mt == (areai+1)]
        peak_cor[sessi,areai,:] = np.unravel_index(temp.argmax(),temp.shape)
        if not any(peak_cor[sessi,areai,:]):
            peak_cor[sessi,areai,:] = [np.nan,np.nan,np.nan]
        peak_cor[sessi,areai,:] = vox2MNI(peak_cor[sessi,areai,:],affine)
    sessi+=1
     
# pre-data & post-data
pre_enum,post_enum = random_split_list(range(len(list(sessid))))
pre_sessid = np.array(sessid)[pre_enum]
post_sessid = np.array(sessid)[post_enum]
for areai in range(areanum):
    pre_volume[:,areai] = volume[:,areai][pre_enum]
    post_volume[:,areai] = volume[:,areai][post_enum]
    pre_mpsc[:,areai] = mpsc[:,areai][pre_enum]
    post_mpsc[:,areai] = mpsc[:,areai][post_enum]
    pre_ppsc[:,areai] = ppsc[:,areai][pre_enum]
    post_ppsc[:,areai] = ppsc[:,areai][post_enum]
    pre_mzstat[:,areai] = mzstat[:,areai][pre_enum]
    post_mzstat[:,areai] = mzstat[:,areai][post_enum]
    pre_pzstat[:,areai] = pzstat[:,areai][pre_enum]
    post_pzstat[:,areai] = pzstat[:,areai][post_enum] 
    for cor in range(3):
        pre_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][pre_enum]
        post_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][post_enum]
   
# make file
# Q3:how to represent peak coordinate

for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'.csv'),'wb') as filecsv:
        writer_total = csv.writer(filecsv)
        writer_total.writerow(['NSPID',
                               'volume',
                               'mean_psc',
                               'peak_psc',
                               'mean_zstate',
                               'peak_zstate',
                               'px','py','pz'])
        wholedata_total = zip(list(sessid),
                          list(volume[:,areai]),
                          list(mpsc[:,areai]),
                          list(ppsc[:,areai]),
                          list(mzstat[:,areai]),
                          list(pzstat[:,areai]),
                          list(peak_cor[:,areai,0]),
                          list(peak_cor[:,areai,1]),
                          list(peak_cor[:,areai,2]))
        writer_total.writerows(wholedata_total)
    filecsv.close()

# pre_enum
for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'_pre'+'.csv'),'wb') as filecsv:
        writer_pre = csv.writer(filecsv)
        writer_pre.writerow(['NSPID',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
        wholedata_pre = zip(list(pre_sessid),
                        list(pre_volume[:,areai]),
                        list(pre_mpsc[:,areai]),
                        list(pre_ppsc[:,areai]),
                        list(pre_mzstat[:,areai]),
                        list(pre_pzstat[:,areai]),
                        list(pre_peak_cor[:,areai,0]),
                        list(pre_peak_cor[:,areai,1]),
                        list(pre_peak_cor[:,areai,2]))
        writer_pre.writerows(wholedata_pre)
    filecsv.close()

# post_enum
for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'_post'+'.csv'),'wb') as filecsv:
        writer_post = csv.writer(filecsv)
        writer_post.writerow(['NSPID',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
        wholedata_post = zip(list(post_sessid),
                        list(post_volume[:,areai]),
                        list(post_mpsc[:,areai]),
                        list(post_ppsc[:,areai]),
                        list(post_mzstat[:,areai]),
                        list(post_pzstat[:,areai]),
                        list(post_peak_cor[:,areai,0]),
                        list(post_peak_cor[:,areai,1]),
                        list(post_peak_cor[:,areai,2]))
        writer_post.writerows(wholedata_post)
    filecsv.close()

# Now,work for probabilistic maps
outpath_prob = os.path.join(outpath,'probabilistic/')
probdata = probatlas(sesspar,sessid,'mt/motion','mt_z5.0_ff.nii.gz',areaname,areaid,outpath_prob)

# MPM image
mpmdata = MPM(probdata,header,0,outpath_prob)

#    df = pd.DataFrame({'NSPID':sessid,
#                      'volume':volume[:,areai],
#                      'psc':psc[:,areai]
#                      ''})
#    df.to_csv(areaname[areai]+'.csv',index=False)
    






